#!/usr/bin/env -S uv run --script

# Released under MIT License.
# Copyright (c) 2025 Ladislav Bartos and Robert Vacha Lab

"""
Check the state of qq jobs in multiple directories.
Version 0.4.
Requires `uv`: https://docs.astral.sh/uv
"""

# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "qq",
# ]
#
# [tool.uv.sources]
# qq = { git = "https://github.com/Ladme/qq.git", tag = "v0.6.1" }
# ///

import argparse
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from contextlib import suppress
from dataclasses import dataclass
from pathlib import Path

from rich.console import Console
from rich.progress import BarColumn, Progress, TextColumn, TimeRemainingColumn

from qq_lib.clear import Clearer
from qq_lib.core.common import get_info_files
from qq_lib.core.error import QQError
from qq_lib.info import Informer
from qq_lib.properties.states import RealState
from qq_lib.submit import Submitter
from qq_lib.wipe import Wiper

console = Console()
# increase logging level to critical
logging.disable(logging.ERROR)


@dataclass(frozen=True)
class Job:
    """Informer and input directory of the job."""

    informer: Informer
    directory: Path


def get_informer(directory: str) -> Informer | None:
    """Get informer for the newest job in the specified directory."""
    # check that the directory is actually a directory and convert it to Path
    if not (directory := Path(directory)).is_dir():
        return None

    # get all info files in the directory
    info_files = get_info_files(directory)

    # if no qq info files are found, return None
    if not info_files:
        return None

    # get the last info file (the newest one) and load it into an informer
    return Informer.fromFile(info_files[-1], None)


def process_directory(directory: str) -> tuple[Job, RealState] | None:
    """Return (Job, state) for use in thread pool."""
    # get informer from the directory
    informer = get_informer(directory)

    # return None, if informer not constructed
    if not informer:
        return None

    # get the state of the job
    state = informer.getRealState()

    return Job(informer, Path(directory)), state


def fix_job(job: Job) -> tuple[Job, bool]:
    """
    Wipe working directory and resubmit the job.
    Returns (Job, True) if successfully resubmitted, else returns (Job, False).
    """
    directory = job.directory
    informer = job.informer

    # ignore if this fails
    with suppress(QQError):
        # delete the working directory
        # no checks since we assume the provided job is killed or failed
        wiper = Wiper.fromInformer(informer)
        wiper.wipe()

        # remove runtime files in the directory
        clearer = Clearer(directory)
        clearer.clear()

    # submit the job again
    try:
        submitter = Submitter(
            informer.batch_system,
            informer.info.queue,
            informer.info.account,
            (directory / informer.info.script_name).resolve(),
            informer.info.job_type,
            informer.info.resources,
            informer.info.loop_info,
            informer.info.excluded_files,
            informer.info.included_files,
            # remove dependencies
        )
        submitter.submit()
        return (job, True)
    except QQError as e:
        console.print(
            f"\n[red bold]ERROR[/red bold]. Could not submit job in directory '{job.directory}': {e}"
        )
        return (job, False)


def get_jobs_and_states(
    directories: list[str], threads: int
) -> dict[RealState, set[Job]]:
    """Get states of the jobs in the directories."""
    n_directories = len(directories)

    # prepare a progress bar
    progress = Progress(
        TextColumn("Collecting job states"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeRemainingColumn(),
        console=console,
        expand=False,
    )

    # `states` maps job states to jobs
    states: dict[RealState, set[Job]] = {}

    # render rich progress bar
    with progress:
        # register a new progress task (for progress bar)
        task = progress.add_task("collect", total=n_directories)

        # create a thread pool for parallel processing of directories
        with ThreadPoolExecutor(max_workers=threads) as executor:
            # submit each directory to the thread pool
            # `futures` maps Future objects to directory names
            futures = {executor.submit(process_directory, d): d for d in directories}

            # iterate over futures as they finish (in arbitrary order)
            for future in as_completed(futures):
                # get the result from the completed task (job, state or None)
                result = future.result()

                # if result is not None
                if result:
                    dirinfo, state = result
                    # add the job to the set associated with its state
                    states.setdefault(state, set()).add(dirinfo)

                # advance the progress bar by once since one directory is done
                progress.update(task, advance=1)

    return states


def fix_jobs(states: dict[RealState, set[Path]]) -> tuple[set[Job], set[Job]]:
    """Fix all failed and killed jobs by deleting their working directories and resubmitting them."""
    # get failed nad killed jobs
    jobs = states.get(RealState.FAILED, set()).union(
        states.get(RealState.KILLED, set())
    )

    if not jobs:
        # nothing to fix
        return set(), set()

    # prepare a progress bar
    progress = Progress(
        TextColumn("Fixing jobs"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeRemainingColumn(),
        console=console,
        expand=False,
    )

    fixed_jobs = set()
    unfixed_jobs = set()
    with progress:
        # register a new progress task (for progress bar)
        task = progress.add_task("fix", total=len(jobs))

        # submitting in qq is not a thread-safe operation,
        # we have to do fixing sequentially
        for job in jobs:
            if fix_job(job)[1]:
                fixed_jobs.add(job)
            else:
                unfixed_jobs.add(job)

            progress.update(task, advance=1)

    return fixed_jobs, unfixed_jobs


def main():
    # parse command line options
    parser = argparse.ArgumentParser(
        "multi-check",
        description="Check the state of qq jobs in multiple directories.",
    )
    parser.add_argument(
        "directories", nargs="+", help="Directories containing qq info files."
    )
    parser.add_argument(
        "-t",
        "--threads",
        type=int,
        default=16,
        help="Number of worker threads (default: 16)",
    )
    parser.add_argument(
        "--fix",
        default=False,
        action="store_true",
        help="Resubmit all failed and killed jobs.",
    )
    args = parser.parse_args()
    console.print()

    # collect the states of the jobs
    states = get_jobs_and_states(args.directories, args.threads)

    # for each state, print the number of jobs in this state
    # and the directories of the corresponding jobs
    console.print()
    # total number of jobs
    total_jobs = 0
    state_keys = sorted(states.keys(), key=lambda x: str(x))
    for state in state_keys:
        # get all directories of jobs in this state
        dirs = [dirinfo.directory for dirinfo in states[state]]

        # number of jobs in this state
        n_jobs = len(dirs)
        total_jobs += n_jobs

        color = state.color

        console.print(
            f"[{color} bold]{str(state).upper():15s}[/{color} bold] [default]{n_jobs}[/default]"
        )
        console.print(f"[grey70]{' '.join(str(x) for x in sorted(dirs))}[/grey70]\n")

    console.print(f"[bold]{'TOTAL':15s}[/bold] [default]{total_jobs}[/default]\n")

    # fix jobs, if requested
    if args.fix:
        console.print("***********************************\n")
        fixed, unfixed = fix_jobs(states)

        if not fixed and not unfixed:
            console.print("[bold]Nothing to fix.[/bold]\n")
            return

        dirs_fixed = [job.directory for job in fixed]
        console.print(
            f"\n[bright_green bold]{'FIXED SUCCESSFULLY':25s}[/bright_green bold] [default]{len(fixed)}[/default]"
        )
        console.print(
            f"[grey70]{' '.join(str(x) for x in sorted(dirs_fixed))}[/grey70]"
        )

        dirs_unfixed = [job.directory for job in unfixed]
        console.print(
            f"\n[bright_red bold]{'COULD NOT FIX':25s}[/bright_red bold] [default]{len(unfixed)}[/default]"
        )
        console.print(
            f"[grey70]{' '.join(str(x) for x in sorted(dirs_unfixed))}[/grey70]\n"
        )


if __name__ == "__main__":
    main()
